#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
StrengthWise è³‡æ–™åº«é·ç§»è…³æœ¬
å¾ Firebase Firestore (JSON) é·ç§»åˆ° Supabase PostgreSQL

ä½¿ç”¨æ–¹å¼:
    python scripts/migrate_to_supabase.py data/database/database_export_for_migration.json
"""

import json
import os
import sys
from typing import Dict, List, Any
from datetime import datetime
from supabase import create_client, Client
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# åˆå§‹åŒ– Supabase Client
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ éŒ¯èª¤ï¼šè«‹è¨­ç½® SUPABASE_URL å’Œ SUPABASE_SERVICE_ROLE_KEY ç’°å¢ƒè®Šæ•¸")
    print("   è«‹è¤‡è£½ .env.example ç‚º .env ä¸¦å¡«å…¥æ­£ç¢ºçš„å€¼")
    sys.exit(1)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

class DataMigrator:
    """è³‡æ–™é·ç§»ä¸»é¡åˆ¥"""
    
    def __init__(self, json_file_path: str):
        self.json_file_path = json_file_path
        self.stats = {
            'users': 0,
            'exercises': 0,
            'workout_plans': 0,
            'workout_exercises': 0,
            'workout_sets': 0,
            'body_parts': 0,
            'exercise_types': 0,
            'notes': 0,
            'errors': []
        }
    
    def run(self):
        """åŸ·è¡Œå®Œæ•´é·ç§»æµç¨‹"""
        print("=" * 60)
        print("ğŸš€ StrengthWise è³‡æ–™åº«é·ç§»")
        print("=" * 60)
        
        # è¼‰å…¥ JSON è³‡æ–™
        print("\nğŸ“‚ è¼‰å…¥è³‡æ–™æª”æ¡ˆ...")
        with open(self.json_file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        collections = data.get('collections', {})
        
        # ä¾åºé·ç§»ï¼ˆæ³¨æ„é †åºï¼šå…ˆçˆ¶è¡¨ï¼Œå¾Œå­è¡¨ï¼‰
        self.migrate_body_parts(collections.get('bodyParts', {}))
        self.migrate_exercise_types(collections.get('exerciseTypes', {}))
        self.migrate_users(collections.get('users', {}))
        self.migrate_exercises(collections.get('exercise', {}))
        self.migrate_workout_plans(collections.get('workoutPlans', {}))
        self.migrate_notes(collections.get('notes', {}))
        
        # è¼¸å‡ºçµ±è¨ˆ
        self.print_stats()
    
    def migrate_users(self, users_data: Dict):
        """é·ç§»ç”¨æˆ¶è³‡æ–™"""
        print("\nğŸ‘¤ é·ç§»ç”¨æˆ¶è³‡æ–™...")
        
        if not users_data or 'sample_documents' not in users_data:
            print("  âš ï¸  ç„¡ç”¨æˆ¶è³‡æ–™")
            return
        
        users_batch = []
        for doc in users_data['sample_documents']:
            user = doc['data']
            users_batch.append({
                'id': doc['id'],
                'email': user.get('email'),
                'display_name': user.get('displayName'),
                'avatar_url': user.get('photoURL'),
                'age': user.get('age'),
                'gender': user.get('gender'),
                'height': user.get('height'),
                'weight': user.get('weight'),
                'unit_system': user.get('unitSystem', 'metric'),
                'is_coach': user.get('isCoach', False),
                'is_student': user.get('isStudent', True),
                'created_at': self.parse_timestamp(user.get('profileCreatedAt')),
                'updated_at': self.parse_timestamp(user.get('profileUpdatedAt'))
            })
        
        if users_batch:
            try:
                response = supabase.table("users").upsert(users_batch).execute()
                self.stats['users'] = len(users_batch)
                print(f"  âœ… æˆåŠŸé·ç§» {len(users_batch)} å€‹ç”¨æˆ¶")
            except Exception as e:
                error_msg = f"é·ç§»ç”¨æˆ¶å¤±æ•—: {e}"
                print(f"  âŒ {error_msg}")
                self.stats['errors'].append(error_msg)
    
    def migrate_exercises(self, exercises_data: Dict):
        """é·ç§»å‹•ä½œåº«"""
        print("\nğŸ’ª é·ç§»å‹•ä½œåº«...")
        
        if not exercises_data or 'sample_documents' not in exercises_data:
            print("  âš ï¸  ç„¡å‹•ä½œè³‡æ–™")
            return
        
        exercises_batch = []
        for doc in exercises_data['sample_documents']:
            exercise = doc['data']
            exercises_batch.append({
                'id': doc['id'],
                'name': exercise.get('name'),
                'name_en': exercise.get('nameEn'),
                'action_name': exercise.get('actionName'),
                'training_type': exercise.get('trainingType'),
                'body_part': exercise.get('bodyPart'),
                'body_parts': exercise.get('bodyParts', []),
                'specific_muscle': exercise.get('specificMuscle'),
                'equipment': exercise.get('equipment'),
                'equipment_category': exercise.get('equipmentCategory'),
                'equipment_subcategory': exercise.get('equipmentSubcategory'),
                'joint_type': exercise.get('jointType'),
                'level1': exercise.get('level1'),
                'level2': exercise.get('level2'),
                'level3': exercise.get('level3'),
                'level4': exercise.get('level4'),
                'level5': exercise.get('level5'),
                'description': exercise.get('description'),
                'image_url': exercise.get('imageUrl'),
                'video_url': exercise.get('videoUrl'),
                'user_id': None,  # ç³»çµ±å…§å»ºå‹•ä½œ
                'created_at': self.parse_timestamp(exercise.get('createdAt'))
            })
        
        # æ‰¹æ¬¡å¯«å…¥ï¼ˆæ¯æ¬¡ 100 ç­†ï¼‰
        batch_size = 100
        for i in range(0, len(exercises_batch), batch_size):
            batch = exercises_batch[i:i+batch_size]
            try:
                supabase.table("exercises").upsert(batch).execute()
                self.stats['exercises'] += len(batch)
                print(f"  âœ… é·ç§»é€²åº¦: {self.stats['exercises']}/{len(exercises_batch)}")
            except Exception as e:
                error_msg = f"é·ç§»å‹•ä½œå¤±æ•— (batch {i}): {e}"
                print(f"  âŒ {error_msg}")
                self.stats['errors'].append(error_msg)
    
    def migrate_workout_plans(self, plans_data: Dict):
        """é·ç§»è¨“ç·´è¨ˆåŠƒï¼ˆåŒ…å« exercises å’Œ setsï¼‰"""
        print("\nğŸ“‹ é·ç§»è¨“ç·´è¨ˆåŠƒ...")
        
        if not plans_data or 'sample_documents' not in plans_data:
            print("  âš ï¸  ç„¡è¨“ç·´è¨ˆåŠƒè³‡æ–™")
            return
        
        for doc in plans_data['sample_documents']:
            plan = doc['data']
            
            # 1. æ’å…¥ workout_plan
            plan_record = {
                'id': doc['id'],
                'user_id': plan.get('userId'),
                'trainee_id': plan.get('traineeId'),
                'creator_id': plan.get('creatorId'),
                'title': plan.get('title'),
                'description': plan.get('description'),
                'plan_type': plan.get('planType'),
                'ui_plan_type': plan.get('uiPlanType'),
                'scheduled_date': self.parse_timestamp(plan.get('scheduledDate')),
                'completed': plan.get('completed', False),
                'completed_date': self.parse_timestamp(plan.get('completedDate')),
                'training_time': self.parse_timestamp(plan.get('trainingTime')),
                'total_exercises': plan.get('totalExercises', 0),
                'total_sets': plan.get('totalSets', 0),
                'total_volume': plan.get('totalVolume', 0),
                'note': plan.get('note'),
                'created_at': self.parse_timestamp(plan.get('createdAt')),
                'updated_at': self.parse_timestamp(plan.get('updatedAt'))
            }
            
            try:
                supabase.table("workout_plans").upsert([plan_record]).execute()
                self.stats['workout_plans'] += 1
                
                # 2. æ’å…¥ workout_exercises å’Œ workout_sets
                exercises = plan.get('exercises', [])
                for idx, exercise in enumerate(exercises):
                    exercise_record = {
                        'workout_plan_id': doc['id'],
                        'exercise_id': exercise.get('exerciseId'),
                        'exercise_name': exercise.get('exerciseName'),
                        'order_index': idx,
                        'completed': exercise.get('completed', False),
                        'rest_time': exercise.get('restTime', 90),
                        'notes': exercise.get('notes')
                    }
                    
                    ex_response = supabase.table("workout_exercises").insert([exercise_record]).execute()
                    workout_exercise_id = ex_response.data[0]['id']
                    self.stats['workout_exercises'] += 1
                    
                    # 3. æ’å…¥ sets
                    sets = exercise.get('sets', [])
                    if isinstance(sets, list):
                        sets_batch = []
                        for set_data in sets:
                            if isinstance(set_data, dict):
                                sets_batch.append({
                                    'workout_exercise_id': workout_exercise_id,
                                    'set_number': set_data.get('setNumber'),
                                    'reps': set_data.get('reps'),
                                    'weight': set_data.get('weight'),
                                    'completed': set_data.get('completed', False),
                                    'timestamp': set_data.get('timestamp'),
                                    'note': set_data.get('note')
                                })
                        
                        if sets_batch:
                            supabase.table("workout_sets").insert(sets_batch).execute()
                            self.stats['workout_sets'] += len(sets_batch)
                
                print(f"  âœ… è¨ˆåŠƒ '{plan.get('title')}' ({len(exercises)} å‹•ä½œ)")
                
            except Exception as e:
                error_msg = f"é·ç§»è¨ˆåŠƒå¤±æ•— ({doc['id']}): {e}"
                print(f"  âŒ {error_msg}")
                self.stats['errors'].append(error_msg)
    
    def migrate_body_parts(self, body_parts_data: Dict):
        """é·ç§»èº«é«”éƒ¨ä½"""
        print("\nğŸ¦´ é·ç§»èº«é«”éƒ¨ä½...")
        
        if not body_parts_data or 'sample_documents' not in body_parts_data:
            print("  âš ï¸  ç„¡èº«é«”éƒ¨ä½è³‡æ–™")
            return
        
        batch = []
        for doc in body_parts_data['sample_documents']:
            part = doc['data']
            batch.append({
                'id': doc['id'],
                'name': part.get('name'),
                'description': part.get('description'),
                'count': part.get('count', 0)
            })
        
        if batch:
            try:
                supabase.table("body_parts").upsert(batch).execute()
                self.stats['body_parts'] = len(batch)
                print(f"  âœ… æˆåŠŸé·ç§» {len(batch)} å€‹èº«é«”éƒ¨ä½")
            except Exception as e:
                error_msg = f"é·ç§»èº«é«”éƒ¨ä½å¤±æ•—: {e}"
                print(f"  âŒ {error_msg}")
                self.stats['errors'].append(error_msg)
    
    def migrate_exercise_types(self, types_data: Dict):
        """é·ç§»å‹•ä½œé¡å‹"""
        print("\nğŸ‹ï¸ é·ç§»å‹•ä½œé¡å‹...")
        
        if not types_data or 'sample_documents' not in types_data:
            print("  âš ï¸  ç„¡å‹•ä½œé¡å‹è³‡æ–™")
            return
        
        batch = []
        for doc in types_data['sample_documents']:
            type_data = doc['data']
            batch.append({
                'id': doc['id'],
                'name': type_data.get('name'),
                'description': type_data.get('description'),
                'count': type_data.get('count', 0)
            })
        
        if batch:
            try:
                supabase.table("exercise_types").upsert(batch).execute()
                self.stats['exercise_types'] = len(batch)
                print(f"  âœ… æˆåŠŸé·ç§» {len(batch)} å€‹å‹•ä½œé¡å‹")
            except Exception as e:
                error_msg = f"é·ç§»å‹•ä½œé¡å‹å¤±æ•—: {e}"
                print(f"  âŒ {error_msg}")
                self.stats['errors'].append(error_msg)
    
    def migrate_notes(self, notes_data: Dict):
        """é·ç§»ç­†è¨˜"""
        print("\nğŸ“ é·ç§»ç­†è¨˜...")
        
        if not notes_data or 'sample_documents' not in notes_data:
            print("  âš ï¸  ç„¡ç­†è¨˜è³‡æ–™")
            return
        
        batch = []
        for doc in notes_data['sample_documents']:
            note = doc['data']
            batch.append({
                'id': doc['id'],
                'user_id': note.get('userId'),
                'title': note.get('title'),
                'text_content': note.get('textContent'),
                'drawing_points': note.get('drawingPoints'),
                'created_at': self.parse_timestamp(note.get('createdAt')),
                'updated_at': self.parse_timestamp(note.get('updatedAt'))
            })
        
        if batch:
            try:
                supabase.table("notes").upsert(batch).execute()
                self.stats['notes'] = len(batch)
                print(f"  âœ… æˆåŠŸé·ç§» {len(batch)} ç­†ç­†è¨˜")
            except Exception as e:
                error_msg = f"é·ç§»ç­†è¨˜å¤±æ•—: {e}"
                print(f"  âŒ {error_msg}")
                self.stats['errors'].append(error_msg)
    
    def parse_timestamp(self, ts):
        """è§£æ Firestore timestamp"""
        if not ts:
            return None
        if isinstance(ts, str):
            # å·²ç¶“æ˜¯ ISO æ ¼å¼
            return ts
        if isinstance(ts, int):
            # Unix timestamp (ms)
            return datetime.fromtimestamp(ts / 1000).isoformat()
        return None
    
    def print_stats(self):
        """è¼¸å‡ºé·ç§»çµ±è¨ˆ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š é·ç§»çµ±è¨ˆ")
        print("=" * 60)
        print(f"ç”¨æˆ¶:         {self.stats['users']}")
        print(f"å‹•ä½œåº«:       {self.stats['exercises']}")
        print(f"è¨“ç·´è¨ˆåŠƒ:     {self.stats['workout_plans']}")
        print(f"è¨“ç·´å‹•ä½œ:     {self.stats['workout_exercises']}")
        print(f"çµ„æ•¸è¨˜éŒ„:     {self.stats['workout_sets']}")
        print(f"èº«é«”éƒ¨ä½:     {self.stats['body_parts']}")
        print(f"å‹•ä½œé¡å‹:     {self.stats['exercise_types']}")
        print(f"ç­†è¨˜:         {self.stats['notes']}")
        print(f"éŒ¯èª¤æ•¸:       {len(self.stats['errors'])}")
        
        if self.stats['errors']:
            print("\nâŒ éŒ¯èª¤æ¸…å–®:")
            for error in self.stats['errors']:
                print(f"  - {error}")
        
        print("=" * 60)

def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹å¼: python migrate_to_supabase.py <json_file_path>")
        print("ç¯„ä¾‹: python scripts/migrate_to_supabase.py data/database/database_export_for_migration.json")
        sys.exit(1)
    
    json_file = sys.argv[1]
    
    if not os.path.exists(json_file):
        print(f"âŒ éŒ¯èª¤ï¼šæª”æ¡ˆä¸å­˜åœ¨ {json_file}")
        sys.exit(1)
    
    migrator = DataMigrator(json_file)
    migrator.run()
    
    print("\nâœ… é·ç§»å®Œæˆï¼")

if __name__ == "__main__":
    main()

